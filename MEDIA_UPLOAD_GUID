# Twitter Media Upload to GridFS - Usage Guide

This guide explains how to use the `upload_media_to_gridfs.py` script to upload your existing Twitter media files from your local laptop to MongoDB GridFS.

## Overview

The `upload_media_to_gridfs.py` script is a standalone utility that:
- Scans your local `twitter-scraper/` directories for media files (images and videos)
- Uploads all media files to MongoDB GridFS for cloud storage
- Updates tweet records with GridFS file IDs
- Handles deduplication using MD5 hashing
- Provides detailed progress reporting and statistics

## Prerequisites

Before running the script, ensure you have:
1. ✅ MongoDB Atlas connection (same as your web app)
2. ✅ MongoDB configuration file (`config/mongodb_config.json`)
3. ✅ Local Twitter media files in `twitter-scraper/*/media_tweets/` directories

## Installation

No additional installation required! The script uses existing dependencies from your project.

## Basic Usage

### 1. Test Run (Dry Run)
First, run a dry run to see what would be uploaded:
```bash
python upload_media_to_gridfs.py --dry-run
```

### 2. Actual Upload
Run the actual upload (this will upload all media files to GridFS):
```bash
python upload_media_to_gridfs.py
```

### 3. Custom Configuration
If your MongoDB config is in a different location:
```bash
python upload_media_to_gridfs.py --config ../config/mongodb_config.json
```

### 4. Custom Path
If your Twitter media is in a different directory:
```bash
python upload_media_to_gridfs.py --path /path/to/twitter-media
```

## What the Script Does

### Phase 1: Scanning
- Searches all `twitter-scraper/*/media_tweets/` directories
- Finds all supported media files (.jpg, .png, .gif, .mp4, .mov, etc.)
- Collects file information (size, type, location)

### Phase 2: Upload
- Uploads each file to MongoDB GridFS
- Uses MD5 hashing to detect and skip duplicates
- Stores metadata (content type, original filename, etc.)

### Phase 3: Tweet Updates
- Finds corresponding `tweets_index.json` files
- Updates tweet records with GridFS file IDs
- Maintains backward compatibility

## Output Example

```
🚀 Starting media upload to MongoDB GridFS
==================================================
🔍 Scanning for media files in: twitter-scraper
  📁 Scanning: twitter-scraper/BasselDiebo_media_20250513_to_20251027/media_tweets
  📁 Scanning: twitter-scraper/keyword_spine_20251001_to_20251027/media_tweets
📊 Found 45 media files

📋 Upload Summary:
   Files to process: 45
   Total size: 156,789,234 bytes
   Estimated upload time: 90.0 seconds

==================================================

📁 Processing folder: BasselDiebo_media_20250513_to_20251027
  ✅ Uploaded: OG_1951419951845159349_media_0.jpg -> GridFS 507f1f77bcf86cd799439011
  ✅ Uploaded: OG_1951469027827876171_media_0.mp4 -> GridFS 507f1f77bcf86cd799439012
  ⏭️  Skipping (duplicate): OG_1951477432520065076_media_0.jpg
  📝 Updated 12 tweets with GridFS references

📁 Processing folder: keyword_spine_20251001_to_20251027
  ✅ Uploaded: OG_1978781449374613791_media_0.mp4 -> GridFS 507f1f77bcf86cd799439013
  ✅ Uploaded: OG_1979454768142782670_media_0.mp4 -> GridFS 507f1f77bcf86cd799439014
  📝 Updated 8 tweets with GridFS references

==================================================
📊 Upload Complete!
   Files found: 45
   Files uploaded: 42
   Files skipped: 2
   Files failed: 0
   Duplicates detected: 1
   Total size uploaded: 148,234,567 bytes
   Upload size: 141.34 MB
```

## Features

### ✅ Smart Duplicate Detection
- Uses MD5 hashing to identify identical files
- Skips duplicates automatically
- Reports how many duplicates were found

### ✅ Progress Reporting
- Real-time upload progress
- Detailed statistics at completion
- File-by-file upload status

### ✅ Metadata Preservation
- Stores original filenames in GridFS
- Preserves file types and sizes
- Maintains upload timestamps

### ✅ Error Handling
- Continues uploading even if individual files fail
- Reports failed uploads separately
- Graceful handling of missing files

### ✅ Batch Processing
- Groups files by tweets folder
- Updates tweets in batches for efficiency
- Maintains data consistency

## Configuration

The script uses the same MongoDB configuration as your web application:
```json
{
  "connection_string": "mongodb+srv://...",
  "database_name": "Beautiful_Spine"
}
```

## Troubleshooting

### Connection Issues
- Ensure your MongoDB Atlas IP whitelist includes your current IP
- Verify connection string in config file
- Check internet connectivity

### File Not Found
- Ensure `twitter-scraper/` directories exist
- Verify media files are in `*/media_tweets/` subdirectories
- Check file permissions

### Memory Issues
- For large datasets, the script processes files sequentially
- Monitor system memory usage during upload
- Consider uploading in smaller batches if needed

## After Upload

Once the upload completes:

1. **Check GridFS Storage**: Media files are now stored in MongoDB GridFS
2. **Web App Integration**: Your web app will automatically use GridFS-stored media
3. **Local Cleanup**: You can optionally delete local media files to save space
4. **Deployment Ready**: All media is now cloud-ready for deployment

## File Structure After Upload

```
MongoDB Database:
├── tweets (with GridFS references)
├── media_files (in GridFS)
└── existing collections...

Local Filesystem:
├── twitter-scraper/ (can be archived/deleted)
└── config/
```

## Benefits

- **🚀 Cloud Ready**: All media available from anywhere
- **💾 Space Efficient**: Removes need for local storage
- **🔄 Backup Safe**: Media stored in MongoDB Atlas backup
- **🌐 Deployment Ready**: Works on any cloud platform
- **🔍 Searchable**: Media metadata stored in database